{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Required Utils\n",
    "\n",
    "Clone the `image-tagging-tools` repo as it has all the required utils and codes from preprocessing the image datasets to training the models and using them to classify the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kk-digital/image-tagging-tools.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the dataset images (Stage 1)\n",
    "\n",
    "Use the `image-dataset-processor` utils from the previously cloned repo to process a directory of images (paths to directory of images or an archived dataset), and computes the images metadata along with its CLIP embeddings and writes the result into a JSON file into `output_folder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r  ./image-tagging-tools/image-dataset-processor/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the module/Utility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './image-tagging-tools/image-dataset-processor/')\n",
    "\n",
    "from ImageDatasetProcessor import ImageDatasetProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set required variables by the utility\n",
    "\n",
    "Initialize the required parameters needed by the dataset preprocessor utility and they are described as follows: \n",
    "\n",
    "* `input_folder` _[str]_ -  path to the directory containing sub-folders of each tag.\n",
    "* `output_folder` _[str]_ - path to the directory where to save the files into it.\n",
    "\n",
    "* `clip_model` _[str]_ - CLIP model to be used\n",
    "\n",
    "* `pretrained` _[str]_ - the pre-trained model to be used for CLIP\n",
    "* `batch_size` _[int]_ -  number of images to process at a time\n",
    "* `num_threads` _[int]_ - the number to be used in this process\n",
    "\n",
    "* `device` _[str]_ -  the device to be used in computing the CLIP embeddings, if `None` is provided then `cuda` will be used if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"\"\n",
    "output_folder = \"\"\n",
    "clip_model = \"ViT-B-32\"\n",
    "pretrained = 'openai'\n",
    "batch_size = 32,\n",
    "num_threads = 4,\n",
    "device = None, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageDatasetProcessor.process_dataset(\n",
    "    dataset_path, \n",
    "    output_folder, \n",
    "    clip_model, \n",
    "    pretrained, \n",
    "    batch_size, \n",
    "    num_threads, \n",
    "    device\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8e93f441cdd34ec3e1aab4168a471abe1992cd5890142962f4e98cab1379cc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
