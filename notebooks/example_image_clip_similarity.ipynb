{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CLIP Vectors to Find Similar Images in Set of Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Platform Check GPU (CUDA) or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print ('[WARNING] CUDA/GPU is not available! Compute-intensive scripts on this notebook will be run on CPU.')\n",
    "    device =  \"cpu\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    print(\"Environment is colab\")\n",
    "elif 'KAGGLE_URL_BASE' in os.environ:\n",
    "    print(\"Environment is kaggle\")\n",
    "else:\n",
    "    print(\"Environment is local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open_clip installation\n",
    "%pip install open_clip_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import torch\n",
    "import open_clip\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Dataset from Mega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount Google Drive\n",
    "Mount your google drive to be used for storing the dataset into it. Note: This step is optional, the dataset can also be saved to Colab session storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount._DEBUG = False\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mega CMD Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mega CMD Requirements\n",
    "!apt install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https\n",
    "!apt --fix-broken install\n",
    "\n",
    "# Mega CMD Download and Installation\n",
    "!wget https://mega.nz/linux/MEGAsync/xUbuntu_18.04/amd64/megacmd-xUbuntu_18.04_amd64.deb\n",
    "!sudo dpkg -i megacmd-xUbuntu_18.04_amd64.deb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset\n",
    "Set download URL in Mega and destination path (in Google Drive or session storage) and download the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import contextlib\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "# Download URL on Mega\n",
    "data_url = 'https://mega.nz/file/sBwG1DqZ#NcN7Q97CJPh5DB-tXGb3a4SV6Bubw9xPFRfqPQ4bmw8'\n",
    "# Destination path for download\n",
    "destination_path = './downloads'\n",
    "os.makedirs(destination_path, exist_ok=True)\n",
    "\n",
    "# Function for printing the download progress\n",
    "def print_progress(proc, stream='stdout'):\n",
    "  newlines = ['\\n', '\\r\\n', '\\r']\n",
    "  stream = getattr(proc, stream)\n",
    "  with contextlib.closing(stream):\n",
    "      while True:\n",
    "          out = []\n",
    "          last = stream.read(1)\n",
    "          # Don't loop forever\n",
    "          if last == '' and proc.poll() is not None:\n",
    "              break\n",
    "          while last not in newlines:\n",
    "              # Don't loop forever\n",
    "              if last == '' and proc.poll() is not None:\n",
    "                  break\n",
    "              out.append(last)\n",
    "              last = stream.read(1)\n",
    "          out = ''.join(out)\n",
    "          yield out\n",
    "\n",
    "# Download dataset\n",
    "cmd = [\"mega-get\", data_url, destination_path]\n",
    "proc = Popen(cmd,stdout=PIPE, stderr=STDOUT, universal_newlines=True)\n",
    "for line in print_progress(proc):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Downloaded ZIP-Archived Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Specify location of downloaded data (zip file)\n",
    "downloaded_data_zip = './downloads/Tile_Generator_Genetic_Algo_V1_16x16-2023-23-2--16-01-20.zip'\n",
    "# Location to extract the zip file to\n",
    "os.makedirs('./datasets/', exist_ok=True)\n",
    "dataset_path = f'./datasets/{os.path.splitext(os.path.split(downloaded_data_zip)[-1])[0]}'\n",
    "\n",
    "with ZipFile(downloaded_data_zip) as zip_object:\n",
    "    zip_object.extractall(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Data Source and Destination Path for Writing Images List and CLIP Vectors JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Data folder must be in the form of normal folder (Unzipped) containing images in PNG or JPG format.\n",
    "input_dir = dataset_path\n",
    "# Path for resulting JSON files\n",
    "img_list_json_path = './image_list.json'\n",
    "clip_vectors_json_path = './image_clip_vectors.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions and Create Hash and CLIP Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hash(file_path, hasher):\n",
    "    # Get file hash\n",
    "    with open(file_path, 'rb') as img_file:\n",
    "        img_bytes = img_file.read()\n",
    "    hasher.update(img_bytes)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def get_clip(clip_model_type = 'ViT-L-14' , pretrained = 'openai'):\n",
    "    # Get CLIP model\n",
    "    clip_model, _, preprocess = open_clip.create_model_and_transforms(clip_model_type,pretrained=pretrained)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    return clip_model , preprocess , device\n",
    "\n",
    "def compute_clip(img, clip_model, preprocess, device):\n",
    "    # Compute the CLIP vector\n",
    "    img = preprocess(img).unsqueeze(0).to(device)\n",
    "    clip_model = clip_model.to(device)\n",
    "    return clip_model.encode_image(img).cpu().detach().numpy()\n",
    "\n",
    "# Hash generator\n",
    "hasher = hashlib.sha256()\n",
    "# CLIP model\n",
    "clip_model, preprocess, device = get_clip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Image List JSON and Image CLIP Vectors JSON Source from Input Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_source_json(input_dir, img_list_json_path, clip_vectors_json_path):\n",
    "\n",
    "    # Placeholder for image files paths\n",
    "    img_list_json = {}\n",
    "    # Placeholder for image clip vectors\n",
    "    clip_vectors_json = {}\n",
    "\n",
    "    print ('[INFO] Running on Data Source...')\n",
    "\n",
    "    # Walking thru files\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "\n",
    "        for file in tqdm(files):\n",
    "            # Get file path\n",
    "            file_path = f'{root}/{file}'\n",
    "            # Check if file is png or jpg\n",
    "            if os.path.splitext(file_path)[-1] == '.png' or os.path.splitext(file_path)[-1] == '.jpg':\n",
    "\n",
    "                try:\n",
    "                    # Get file hash\n",
    "                    hash_id = get_hash(file_path, hasher)\n",
    "                    # Compute CLIP Vector\n",
    "                    img = Image.open(file_path)\n",
    "                    clip_vector = compute_clip(img, clip_model, preprocess, device)\n",
    "\n",
    "                    # Image list dictionary creation\n",
    "                    img_list_json[hash_id]={'file_path':file_path, 'file_name':file}\n",
    "                    # CLIP vectors dictionary creation\n",
    "                    clip_vectors_json[hash_id]={'clip_vector':clip_vector.tolist()}\n",
    "\n",
    "                except Exception as e:\n",
    "                    print [f'[WARNING] Error when processing file: {e}']\n",
    "                    return {}, {}\n",
    "\n",
    "    # Writing to file\n",
    "    with open (img_list_json_path, 'w') as file:\n",
    "        json.dump(img_list_json, file, indent=4)    \n",
    "    \n",
    "    with open (clip_vectors_json_path, 'w') as file:\n",
    "        json.dump(clip_vectors_json, file, indent=4)  \n",
    "    \n",
    "    # Number of images\n",
    "    n_images = len(img_list_json)\n",
    "    print (f'[INFO] Completed. Number of images: {n_images}')\n",
    "\n",
    "    return img_list_json, clip_vectors_json\n",
    "\n",
    "# Run the function\n",
    "img_list_json, clip_vectors_json = create_data_source_json(input_dir, img_list_json_path, clip_vectors_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Data Back From File List JSON and Image CLIP Vector JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify again the location of JSON Files\n",
    "img_list_json_path = './image_list.json'\n",
    "clip_vectors_json_path = './image_clip_vectors.json'\n",
    "\n",
    "# Get dictionary of image file paths\n",
    "with open (img_list_json_path, 'r') as file:\n",
    "    img_list_json = json.load(file)\n",
    "\n",
    "# Get dictionary of image CLIP vectors\n",
    "with open (clip_vectors_json_path, 'r') as file:\n",
    "    clip_vectors_json = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get 1 Random 'Reference' Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of hashes (keys in data_dict)\n",
    "hash_list = list(img_list_json.keys())\n",
    "# Get random hash\n",
    "ref_file_hash = random.choice(hash_list)\n",
    "\n",
    "# Reference Image File Path\n",
    "ref_file_path = img_list_json[ref_file_hash]['file_path']\n",
    "# Reference Image CLIP Vector\n",
    "ref_file_clip_vector = np.array(clip_vectors_json[ref_file_hash]['clip_vector'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Dot Product Between Reference Image CLIP Vector and All Other Images CLIP Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity function definition\n",
    "def get_hashes_with_similar_clip(ref_file_hash, ref_file_clip_vector, clip_vectors_json, n_top_similar):\n",
    "    '''\n",
    "    Return list containing pair tupple of dot product and hash with the following structure\n",
    "    [(<dot_product>, <sample_image_hash>), ...]\n",
    "    '''\n",
    "    dot_products = []\n",
    "    # Get top n similar images based on dot products score\n",
    "    n_top_similar = 8\n",
    "\n",
    "    for key in clip_vectors_json.keys():\n",
    "        if key == ref_file_hash:\n",
    "            # If it is an hash of reference image then ignore the clip vector\n",
    "            continue\n",
    "\n",
    "        '''Calculate dot product'''\n",
    "        # Normalize reference vector and sample vector\n",
    "        norm_ref_file_clip_vector = ref_file_clip_vector / linalg.norm(ref_file_clip_vector)\n",
    "        sample_clip_vector = np.array(clip_vectors_json[key]['clip_vector'][0])\n",
    "        norm_sample_clip_vector = sample_clip_vector / linalg.norm(sample_clip_vector)\n",
    "        \n",
    "        # Calculate dot product\n",
    "        dot_product = np.dot(norm_ref_file_clip_vector, norm_sample_clip_vector)\n",
    "        \n",
    "        # Appending dot product result to list\n",
    "        sample_hash = key\n",
    "        dot_products.append((dot_product, sample_hash))\n",
    "\n",
    "    dot_products.sort(reverse=True)\n",
    "\n",
    "    return dot_products[:n_top_similar]\n",
    "\n",
    "# Specify top n images to display\n",
    "n_top_similar = 8\n",
    "\n",
    "# Run the function\n",
    "top_similar_images = get_hashes_with_similar_clip(ref_file_hash, ref_file_clip_vector, clip_vectors_json, n_top_similar)\n",
    "print (top_similar_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Reference Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show reference image\n",
    "plt.imshow(Image.open(ref_file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Top Similar Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 'n_top_similar' most similar images. Similarity ranking: from left to right.\n",
    "\n",
    "fig, ax = plt.subplots(1, n_top_similar, figsize = (20,20))\n",
    "\n",
    "print ('[INFO] Showing Similar Images. Similarity ranking: from left to right.')\n",
    "i=0\n",
    "for item in tqdm(top_similar_images):\n",
    "    '''\n",
    "    item has the following structure\n",
    "    [[<dot_product>, <sample_image_hash>, ...]\n",
    "    '''\n",
    "    sample_image_hash = item[1]\n",
    "    file_path = img_list_json[sample_image_hash]['file_path']\n",
    "    ax[i].imshow(Image.open(file_path))\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "c518711542db1b7752d0b1005bb6b1db13084b2ce60111ae8895922158ddc3d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
