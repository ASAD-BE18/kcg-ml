{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThYBpsZwvw53"
      },
      "source": [
        "**Import the required modules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rwb4-GCQvkWJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    print ('[WARNING] CUDA/GPU is not available! Compute-intensive scripts on this notebook will be run on CPU.')\n",
        "    device =  \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuz4H21sFYsP"
      },
      "source": [
        "Clone the kcg-ml repo as it has all the required utils and codes from preprocessing the image datasets to training the models and using them to classify the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eQfH-HmEiqw",
        "outputId": "7694a377-9ec9-41b3-99a3-ab46575cd90e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'kcg-ml'...\n",
            "remote: Enumerating objects: 3060, done.\u001b[K\n",
            "remote: Counting objects: 100% (1052/1052), done.\u001b[K\n",
            "remote: Compressing objects: 100% (423/423), done.\u001b[K\n",
            "remote: Total 3060 (delta 666), reused 956 (delta 624), pack-reused 2008\u001b[K\n",
            "Receiving objects: 100% (3060/3060), 26.62 MiB | 18.37 MiB/s, done.\n",
            "Resolving deltas: 100% (1813/1813), done.\n",
            "/content/kcg-ml\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kk-digital/kcg-ml\n",
        "%cd kcg-ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YgtDjEEGwZS7"
      },
      "outputs": [],
      "source": [
        "#@title Download Dataset\n",
        "%%capture\n",
        "# Mega CMD Requirements\n",
        "!apt install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https\n",
        "!apt --fix-broken install\n",
        "\n",
        "# Mega CMD Download and Installation\n",
        "!wget https://mega.nz/linux/MEGAsync/xUbuntu_18.04/amd64/megacmd-xUbuntu_18.04_amd64.deb\n",
        "!sudo dpkg -i megacmd-xUbuntu_18.04_amd64.deb\n",
        "\n",
        "import os\n",
        "import contextlib\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "\n",
        "# Download URL on Mega\n",
        "tagged_dataset_url = 'https://mega.nz/file/8RhFRISJ#vlQhjBp5hrNtQzFnRVQtD_ilHfIyLOSrlwVXEb3t1UM'\n",
        "#other_dataset_url  = 'https://mega.nz/file/5FhGkRjD#yFihfhr1RMHfPTffhPB4tQtJsnn_HBYFOSfqdPOrp78'\n",
        "# Destination path for download\n",
        "destination_path = './downloads'\n",
        "os.makedirs(destination_path, exist_ok=True)\n",
        "\n",
        "# Function for printing the download progress\n",
        "def print_progress(proc, stream='stdout'):\n",
        "  newlines = ['\\n', '\\r\\n', '\\r']\n",
        "  stream = getattr(proc, stream)\n",
        "  with contextlib.closing(stream):\n",
        "      while True:\n",
        "          out = []\n",
        "          last = stream.read(1)\n",
        "          # Don't loop forever\n",
        "          if last == '' and proc.poll() is not None:\n",
        "              break\n",
        "          while last not in newlines:\n",
        "              # Don't loop forever\n",
        "              if last == '' and proc.poll() is not None:\n",
        "                  break\n",
        "              out.append(last)\n",
        "              last = stream.read(1)\n",
        "          out = ''.join(out)\n",
        "          yield out\n",
        "\n",
        "# Download dataset\n",
        "for data_url in [tagged_dataset_url]:\n",
        "  cmd = [\"mega-get\", data_url, destination_path]\n",
        "  proc = Popen(cmd,stdout=PIPE, stderr=STDOUT, universal_newlines=True)\n",
        "  for line in print_progress(proc):\n",
        "    print(line)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the dataset\n",
        "%%capture\n",
        "!unzip /content/kcg-ml/downloads/pixel-art-tagged-v3.zip"
      ],
      "metadata": {
        "id": "IxmHmNEwEV7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# add the required datasets and zip again\n",
        "!zip -r ./datasets/tagged_dataset.zip ./pixel-art-tagged-v3/pos-pixel-art-environmental ./pixel-art-tagged-v3/other-training ./pixel-art-tagged-v3/other-validation"
      ],
      "metadata": {
        "id": "dvNr9_vkIEHn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BPcwMQ2ep_e"
      },
      "source": [
        "**Generate the CLIP vectors of the images and train the Logistic Regression Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WFGczIWZv4TF"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install ascii_graph open_clip_torch patool fire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DP-2dz42FeaC"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, './image_classifier_pipeline/data_loader/')\n",
        "from ImageDatasetProcessor import ImageDatasetProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BZErZwtIhEej"
      },
      "outputs": [],
      "source": [
        "dataset_path = './datasets/tagged_dataset.zip'\n",
        "output_folder = './output'\n",
        "tagged_dataset = True\n",
        "clip_model = 'ViT-L-14'\n",
        "pretrained = 'laion2b_s32b_b82k'\n",
        "batch_size = 32\n",
        "num_threads = 4\n",
        "device = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESKtoSj0GTSz",
        "outputId": "01a35d61-811f-476e-bdd6-7f5742cfe5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patool: Extracting ./datasets/tagged_dataset.zip ...\n",
            "patool: running /usr/bin/7z x -o./datasets/tagged_dataset-decompressed-tmp -- ./datasets/tagged_dataset.zip\n",
            "patool: ... ./datasets/tagged_dataset.zip extracted to `./datasets/tagged_dataset-decompressed-tmp'.\n",
            "is archive dataset\n",
            "dataset folder path  = ./datasets/tagged_dataset-decompressed-tmp/pixel-art-tagged-v3\n",
            "[WARNING] problem with ./datasets/tagged_dataset-decompressed-tmp/pixel-art-tagged-v3/other-validation/https___i.pinimg.com_originals_00_92_c4_0092c473456acd2e4819da18ac964760.gif, cannot identify image file './datasets/tagged_dataset-decompressed-tmp/pixel-art-tagged-v3/other-validation/https___i.pinimg.com_originals_00_92_c4_0092c473456acd2e4819da18ac964760.gif'\n",
            "[WARNING] file ./datasets/tagged_dataset-decompressed-tmp/pixel-art-tagged-v3/other-validation/https___i.pinimg.com_originals_00_92_c4_0092c473456acd2e4819da18ac964760.gif is not supported and will be ignored\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:52<00:00,  2.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Writing to database table in ./output/image_dataset_cache.sqlite\n",
            "[INFO] Finished.\n"
          ]
        }
      ],
      "source": [
        "ImageDatasetProcessor.process_dataset(\n",
        "    dataset_path, \n",
        "    output_folder,\n",
        "    tagged_dataset, \n",
        "    clip_model, \n",
        "    pretrained,\n",
        "    batch_size, \n",
        "    num_threads, \n",
        "    device\n",
        ")\n",
        "\n",
        "# clean the temp storage\n",
        "!rm -rf ./datasets/tagged_dataset-decompressed-tmp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K Multilinear Logistic Regression**"
      ],
      "metadata": {
        "id": "FkjE-qDSRbwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('./image_classifier_pipeline/model_api/')\n",
        "import warnings\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from logistic_regression_pytorch import LogisticRegressionPytorch\n",
        "from train_helper_functions import *\n",
        "from model_api import ModelApi\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "# Number of Logistic Regression Models to train\n",
        "K = 10"
      ],
      "metadata": {
        "id": "MlDIbWUgLbd4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run from ./image-tagging-tools directory\n",
        "# parameters required to train the model\n",
        "metadata_json = './output/input-metadata.json' \n",
        "tag_to_hash_json = './output/input-tag-to-image-hash-list.json'\n",
        "output_dir = './output'\n",
        "test_per = 0.5 # percentage of the test data"
      ],
      "metadata": {
        "id": "IgPNNNeoRwap"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "        metadata_json    : str, \n",
        "        tag_to_hash_json : str,\n",
        "        output_dir : str, \n",
        "        test_per : float,\n",
        "        shuffle : bool = True,\n",
        "        ):\n",
        "    \"\"\"main function to be running, calls other function for making trained models pickle files,\n",
        "    and making of mapping files.\n",
        "\n",
        "    :param metadata_json: path to the metadata json file containg embeddings and tags.\n",
        "    :type metadata_json: str\n",
        "    :param tag_to_hash_json: path to tag-to-hash json file containg embeddings and tags.\n",
        "    :type tag_to_hash_json: str\n",
        "    :param output_dir: directory for the classification models pickle files and mappings jsons. \n",
        "    :type output_dir: str\n",
        "    :param test_per: percentage of the test embeddings \n",
        "    :type test_per: float\n",
        "    :param shuffle: shuffle the data, defaults to True\n",
        "    :type shuffle: bool, optional\n",
        "    :rtype: None\n",
        "    \"\"\"\n",
        "\n",
        "    # Classifier Model API opject\n",
        "    model_api = ModelApi()\n",
        "\n",
        "    # load tag to hash json and metadata json.\n",
        "    metadata_dict    = load_json(metadata_json)\n",
        "    tag_to_hash_json = load_json(tag_to_hash_json)\n",
        "    if metadata_dict is None or tag_to_hash_json is None : # Problem happened with the json file loading.\n",
        "        return\n",
        "\n",
        "    # Get training start time\n",
        "    t_start = datetime.now()\n",
        "    # get the two output folder paths (models and reports) with respect to \\\n",
        "    # the output directory provided in the script.\n",
        "    report_out_folder , models_out_folder = check_out_folder(output_dir) \n",
        "\n",
        "    # other training and other validation embeddings lists.\n",
        "    other_all_emb_list     = [metadata_dict[hash_id][\"embeddings_vector\"] for hash_id in tag_to_hash_json['other-training']]\n",
        "    other_val_all_emb_list = [metadata_dict[hash_id][\"embeddings_vector\"] for hash_id in tag_to_hash_json['other-validation']]\n",
        "\n",
        "    # check if the shuffle flag is true, shuffle the data.\n",
        "    if shuffle:\n",
        "        np.random.shuffle(other_all_emb_list)\n",
        "        np.random.shuffle(other_val_all_emb_list)\n",
        "\n",
        "    # get embeddings from tag_emb_dict and make it reay for training the classifier \n",
        "    for tag in tag_to_hash_json:\n",
        "\n",
        "        # make sure that it's a pixel art class tag. \n",
        "        if tag in ['other-training' ,'other-validation']:\n",
        "            continue\n",
        "\n",
        "        # get embedding list of tag images.\n",
        "        tag_all_emb_list = [metadata_dict[hash_id][\"embeddings_vector\"] for hash_id in tag_to_hash_json[tag]]\n",
        "\n",
        "        # check if the shuffle flag is true, shuffle the data.\n",
        "        if shuffle:\n",
        "            np.random.shuffle(tag_all_emb_list)\n",
        "\n",
        "        # get train test embeddings and labels.\n",
        "        train_emb, train_labels, test_emb, test_labels , t_n , o_n = get_train_test(tag_all_emb_list, other_all_emb_list , test_per)\n",
        "        \n",
        "        # torch-logistic-regression \n",
        "        model_type = 'torch-logistic-regression'\n",
        "\n",
        "        # Check if classifier model with model_type and tag already exist.\n",
        "        model = model_api.get_model_by_type_tag(model_type, tag)\n",
        "\n",
        "        if len(model)>0:\n",
        "                # Existing classifier model with model_type and tag found. Do not create new one\n",
        "                print (f'Classifier model for type: {model_type} and tag: {tag} already exist. Training will use existing model')\n",
        "                classifier = model['classifier']\n",
        "                print (f\"MODEL TYPE {model_type}, {model['model_type']}\")\n",
        "        else:\n",
        "            # No existing classifier model with model_type and tag. Initialize new classifier model\n",
        "            print (f'Initialize new classifier model for type: {model_type} and tag: {tag}')\n",
        "            classifier = LogisticRegressionPytorch(output_dim=1)\n",
        "            \n",
        "        classifier = train_loop(model = classifier, train_emb=train_emb, train_labels=train_labels)\n",
        "            \n",
        "\n",
        "        test_emb = torch.from_numpy(test_emb.astype(np.float32))\n",
        "        predictions = classifier(test_emb)\n",
        "        predictions = predictions.round().view(1,-1).squeeze().detach().numpy()\n",
        "            \n",
        "        # get histogram data.\n",
        "        in_tag_tagged  = histogram_list(np.array(tag_all_emb_list), classifier, other=False, using_torch=(model_type == 'torch-logistic-regression')) # histogram data for in-tag images \n",
        "        out_tag_tagged = histogram_list(np.array(other_val_all_emb_list), classifier,  other=True, using_torch=(model_type == 'torch-logistic-regression')) # histogram data for out-tag images\n",
        "            \n",
        "        # put all lines for text file report in one .\n",
        "        text_file_lines = [ f\"model: {model_type}\\n\", \"task: binary-classification\\n\",\n",
        "                                f\"tag: [{tag}]\\n\\n\", f\"tag-set-image-count:   {len(tag_all_emb_list)} \\n\",\n",
        "                                f\"other-set-image-count: {len(other_all_emb_list)} \\n\",\n",
        "                                f'validation-tag-image-count   : {t_n}  \\n',f'validation-other-image-count : {o_n}  \\n\\n']\n",
        "        # text_file_lines.extend(calc_confusion_matrix(test_labels ,predictions, tag)) \n",
        "        # text_file_lines.extend(histogram_lines(in_tag_tagged, 'in-distribution'))  \n",
        "        # text_file_lines.extend(histogram_lines(out_tag_tagged,'out-distribution')) \n",
        "        # generate report for ovr logistic regression model.\n",
        "        generate_report(report_out_folder , tag , text_file_lines , model_name=model_type)\n",
        "        # generate model pickle file.\n",
        "        generate_model_file(models_out_folder, classifier, model_type, t_start, tag)\n",
        "\n",
        "    print(\"[INFO] Finished.\")"
      ],
      "metadata": {
        "id": "JvArEKJHFrAN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "s72jGZs5T-Uf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e68d58c-5570-49ce-8f2d-0b60a002b0fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialize new classifier model for type: torch-logistic-regression and tag: pos-pixel-art-environmental\n",
            "[INFO] Finished.\n"
          ]
        }
      ],
      "source": [
        "# train K models\n",
        "for _ in range(K):\n",
        "  main(\n",
        "      metadata_json = metadata_json,\n",
        "      tag_to_hash_json = tag_to_hash_json,\n",
        "      output_dir = output_dir,\n",
        "      test_per = test_per\n",
        "      shuffle=True\n",
        "  )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}