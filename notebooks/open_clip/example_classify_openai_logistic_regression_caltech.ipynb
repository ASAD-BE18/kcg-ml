{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzDaTSk4zZaE"
   },
   "source": [
    "## This for just testing the classification between two classes from Caltech100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Platform Check GPU (CUDA) or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    print ('[WARNING] CUDA/GPU is not available! Compute-intensive scripts on this notebook will be run on CPU.')\n",
    "    device =  \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    print(\"Environment is colab\")\n",
    "elif 'KAGGLE_URL_BASE' in os.environ:\n",
    "    print(\"Environment is kaggle\")\n",
    "else:\n",
    "    print(\"Environment is local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfeXU4J1ylSo"
   },
   "outputs": [],
   "source": [
    "#@title Download Dataset\n",
    "%%capture\n",
    "!wget https://data.caltech.edu/records/nyy15-4j048/files/256_ObjectCategories.tar\n",
    "!tar -xvf /content/256_ObjectCategories.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eWkSHNfRzX43"
   },
   "outputs": [],
   "source": [
    "#@title Install OpenCLIP\n",
    "%%capture\n",
    "!pip install open_clip_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j1KmWlxKzk4y"
   },
   "outputs": [],
   "source": [
    "#@title Imports\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import open_clip\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7vLIqtkhznMC"
   },
   "outputs": [],
   "source": [
    "#@title Delete Unwanted Folders and Make Only Two Classes\n",
    "directory = '/content/256_ObjectCategories' # Directory holds all the image's folders\n",
    "dir_list  =     ['029.cannon' , '026.cake' , '027.calculator' ,\n",
    "                '025.cactus','028.camel' , '024.butterfly'] # List of all the wnated folders \n",
    "# Remove other folders\n",
    "for folder in os.listdir(directory):\n",
    "    f = os.path.join(directory, folder)    \n",
    "    if folder not in dir_list:\n",
    "      !rm -r $f\n",
    "      continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFb5DWxnz0aG",
    "outputId": "886e8279-fa18-4bc8-c1bc-427be0d99d5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 354M/354M [00:05<00:00, 64.5MiB/s]\n"
     ]
    }
   ],
   "source": [
    "#@title Clip Model\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32',pretrained='openai')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WEDfQidiz2yp"
   },
   "outputs": [],
   "source": [
    "#@title get features function from OpenAI CLIP Github\n",
    "# https://github.com/openai/CLIP#linear-probe-evaluation\n",
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in DataLoader(dataset, batch_size=100):\n",
    "            features = model.encode_image(images.to(device))\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KCzcJIWYz6Vc"
   },
   "outputs": [],
   "source": [
    "#@title Making Dataset Out Of Images' folder\n",
    "import random\n",
    "transform = preprocess\n",
    "dataset = torchvision.datasets.ImageFolder(directory, transform)\n",
    "n = len(dataset)  # total number of examples\n",
    "n_test = int(0.1 * n)  # take ~10% for test\n",
    "\n",
    "test_list = [] \n",
    "while len(test_list) < n_test:\n",
    "  rand = random.randint(0, n)\n",
    "  if rand not in test_list:\n",
    "    test_list.append(rand)\n",
    "\n",
    "train_list = []\n",
    "for num in range(n):\n",
    "  if num not in test_list:\n",
    "    train_list.append(num)\n",
    "\n",
    "test_set = torch.utils.data.Subset(dataset, test_list,)  # take 10%\n",
    "train_set = torch.utils.data.Subset(dataset, train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UycV50yq0D47",
    "outputId": "614d8a31-5441-4832-9816-f991a231b6eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['024.butterfly',\n",
       " '025.cactus',\n",
       " '026.cake',\n",
       " '027.calculator',\n",
       " '028.camel',\n",
       " '029.cannon']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "XsldxbhN0F28"
   },
   "outputs": [],
   "source": [
    "#@title  Calculating images' features for train/test sets.\n",
    "train_features, train_labels = get_features(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5bKpfVNUbol2"
   },
   "outputs": [],
   "source": [
    "test_features, test_labels = get_features(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FbUqXAuL0JHF",
    "outputId": "43815ade-ab9d-4bd1-97e7-75325218bda8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, 2, 5, 4, 3, 0, 1, 1, 0, 1, 3, 5, 5, 1, 1, 2, 1, 5, 1, 0,\n",
       "       3, 0, 2, 5, 4, 1, 5, 3, 2, 5, 5, 3, 2, 3, 1, 3, 3, 1, 2, 4, 4, 4,\n",
       "       0, 3, 5, 5, 1, 2, 2, 1, 2, 0, 2, 1, 0, 3, 2, 0, 1, 4, 1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRhkiz_s9BWw"
   },
   "source": [
    "# Using LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRSqSSbd9G_N",
    "outputId": "2b26f01d-2284-4e63-ee08-5590483dd48b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 100.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  \n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Calculate the image features\n",
    "train_features, train_labels = get_features(train_set)\n",
    "test_features, test_labels = get_features(test_set)\n",
    "\n",
    "# Perform logistic regression\n",
    "## max_iter reduced to 100 \n",
    "classifier = LogisticRegression(random_state=0, max_iter=1000, verbose=1)\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate using the logistic regression classifier\n",
    "predictions = classifier.predict(test_features)\n",
    "accuracy = np.mean((test_labels == predictions).astype(np.float)) * 100.\n",
    "print(f\"Accuracy = {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMjQE4B3_nT0",
    "outputId": "27988564-1279-4891-bc5b-fc64fae993c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, 2, 5, 4, 3, 0, 1, 1, 0, 1, 3, 5, 5, 1, 1, 2, 1, 5, 1, 0,\n",
       "       3, 0, 2, 5, 4, 1, 5, 3, 2, 5, 5, 3, 2, 3, 1, 3, 3, 1, 2, 4, 4, 4,\n",
       "       0, 3, 5, 5, 1, 2, 2, 1, 2, 0, 2, 1, 0, 3, 2, 0, 1, 4, 1, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxRjnOuHAU8f",
    "outputId": "c8266daa-f573-4355-b725-0a8aa6959ec1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 1, 2, 5, 4, 3, 0, 1, 1, 0, 1, 3, 5, 5, 1, 1, 2, 1, 5, 1, 0,\n",
       "       3, 0, 2, 5, 4, 1, 5, 3, 2, 5, 5, 3, 2, 3, 1, 3, 3, 1, 2, 4, 4, 4,\n",
       "       0, 3, 5, 5, 1, 2, 2, 1, 2, 0, 2, 1, 0, 3, 2, 0, 1, 4, 1, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8QIAb0KAW4q",
    "outputId": "95327b0f-82d7-4fc2-db9c-735f7ed6499d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classsifying the images in the butterfly directoy\n",
      "024.butterfly\n",
      "024.butterfly\n",
      "024.butterfly\n",
      "024.butterfly\n",
      "024.butterfly\n",
      "024.butterfly\n",
      "024.butterfly\n",
      "024.butterfly\n",
      "024.butterfly\n"
     ]
    }
   ],
   "source": [
    "#@title Test LogisticRegression using internet images\n",
    "from PIL import Image\n",
    "images_dir = '/content/drive/MyDrive/Brandon/butterflies'\n",
    "print(\"Classsifying the images in the butterfly directoy\")\n",
    "for file_name in os.listdir(images_dir):\n",
    "  image_path = os.path.join(images_dir , file_name)\n",
    "  image = preprocess(Image.open(image_path)).unsqueeze(0)\n",
    "  image_features =  model.encode_image(image)\n",
    "  print(dataset.classes[classifier.predict(image_features.detach().numpy()).item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkNdV3K1Ezse",
    "outputId": "e3d63fb9-5edf-440b-de5b-86ac7f6e4c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classsifying the images in the claculators directoy\n",
      "027.calculator\n",
      "027.calculator\n",
      "027.calculator\n",
      "027.calculator\n",
      "027.calculator\n",
      "027.calculator\n",
      "027.calculator\n",
      "027.calculator\n",
      "027.calculator\n",
      "027.calculator\n",
      "027.calculator\n",
      "027.calculator\n"
     ]
    }
   ],
   "source": [
    "images_dir = '/content/drive/MyDrive/Brandon/calculators'\n",
    "print(\"Classsifying the images in the claculators directoy\")\n",
    "for file_name in os.listdir(images_dir):\n",
    "  image_path = os.path.join(images_dir , file_name)\n",
    "  image = preprocess(Image.open(image_path)).unsqueeze(0)\n",
    "  image_features =  model.encode_image(image)\n",
    "  print(dataset.classes[classifier.predict(image_features.detach().numpy()).item()])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
