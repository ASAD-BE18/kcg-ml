{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CLIP Vectors to Find Similar Images in Set of Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import torch\n",
    "import open_clip\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Data Source and Path for Writing JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Data folder must be Unzipped first\n",
    "#input_dir = '../../dataset/Tile_Generator_Genetic_Algo_V1_16x16-2023-23-2--16-01-20'\n",
    "input_dir = '../../dataset/ga_sub'\n",
    "# Path for resulting JSON files\n",
    "img_list_json_path = '../../output/image_list.json'\n",
    "clip_vectors_json_path = '../../output/image_clip_vectors.json'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP Functions Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hash(file_path, hasher):\n",
    "    # Get file hash\n",
    "    with open(file_path, 'rb') as img_file:\n",
    "        img_bytes = img_file.read()\n",
    "    hasher.update(img_bytes)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def get_clip(clip_model_type = 'ViT-B-32' , pretrained = 'openai'):\n",
    "    # Get CLIP model\n",
    "    clip_model, _, preprocess = open_clip.create_model_and_transforms(clip_model_type,pretrained=pretrained)\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    return clip_model , preprocess , device\n",
    "\n",
    "def compute_clip(img, clip_model, preprocess, device):\n",
    "    # Compute the CLIP vector\n",
    "    img = preprocess(img).unsqueeze(0).to(device)\n",
    "    return clip_model.encode_image(img).detach().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Hash and CLIP Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash generator\n",
    "hasher = hashlib.sha256()\n",
    "# CLIP model\n",
    "clip_model, preprocess, device = get_clip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Image List JSON and Image CLIP Vectors JSON Source from Input Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_source_json(input_dir, img_list_json_path, clip_vectors_json_path):\n",
    "\n",
    "    # Placeholder for image files paths\n",
    "    img_list_json = {}\n",
    "    # Placeholder for image clip vectors\n",
    "    clip_vectors_json = {}\n",
    "\n",
    "    print ('[INFO] Running on Data Source...')\n",
    "\n",
    "    # Walking thru files\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "\n",
    "        for file in tqdm(files):\n",
    "            # Get file path\n",
    "            file_path = f'{root}/{file}'\n",
    "            # Check if file is png or jpg\n",
    "            if os.path.splitext(file_path)[-1] == '.png' or os.path.splitext(file_path)[-1] == '.jpg':\n",
    "\n",
    "                try:\n",
    "                    # Get file hash\n",
    "                    hash_id = get_hash(file_path, hasher)\n",
    "                    # Compute CLIP Vector\n",
    "                    img = Image.open(file_path)\n",
    "                    clip_vector = compute_clip(img, clip_model, preprocess, device)\n",
    "\n",
    "                    # Image list dictionary creation\n",
    "                    img_list_json[hash_id]={'file_path':file_path, 'file_name':file}\n",
    "                    # CLIP vectors dictionary creation\n",
    "                    clip_vectors_json[hash_id]={'clip_vector':clip_vector.tolist()}\n",
    "\n",
    "                except Exception as e:\n",
    "                    print [f'[WARNING] Error when processing file: {e}']\n",
    "                    return {}, {}\n",
    "\n",
    "    # Writing to file\n",
    "    with open (img_list_json_path, 'w') as file:\n",
    "        json.dump(img_list_json, file, indent=4)    \n",
    "    \n",
    "    with open (clip_vectors_json_path, 'w') as file:\n",
    "        json.dump(clip_vectors_json, file, indent=4)  \n",
    "    \n",
    "    # Number of images\n",
    "    n_images = len(img_list_json)\n",
    "    print (f'[INFO] Completed. Number of images: {n_images}')\n",
    "\n",
    "    return img_list_json, clip_vectors_json\n",
    "\n",
    "# Run the function\n",
    "img_list_json, clip_vectors_json = create_data_source_json(input_dir, img_list_json_path, clip_vectors_json_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading The Data Back From File List JSON and Image CLIP Vector JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify again the location of JSON Files\n",
    "img_list_json_path = '../../output/image_list.json'\n",
    "clip_vectors_json_path = '../../output/image_clip_vectors.json'\n",
    "\n",
    "# Get dictionary of image file paths\n",
    "with open (img_list_json_path, 'r') as file:\n",
    "    img_list_json = json.load(file)\n",
    "\n",
    "# Get dictionary of image CLIP vectors\n",
    "with open (clip_vectors_json_path, 'r') as file:\n",
    "    clip_vectors_json = json.load(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get 1 Random 'Reference' Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of hashes (keys in data_dict)\n",
    "hash_list = list(img_list_json.keys())\n",
    "# Get random hash\n",
    "ref_file_hash = random.choice(hash_list)\n",
    "\n",
    "# Reference Image File Path\n",
    "ref_file_path = img_list_json[ref_file_hash]['file_path']\n",
    "# Reference Image CLIP Vector\n",
    "ref_clip_vector = np.array(clip_vectors_json[ref_file_hash]['clip_vector'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Dot Product Between Reference Image CLIP Vector and All Other Images CLIP Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity function definition\n",
    "def get_hashes_with_similar_clip(ref_file_hash, clip_vectors_json, n_top_similar):\n",
    "    '''\n",
    "    Return list containing pair tupple of dot product and hash with the following structure\n",
    "    [(<dot_product>, <sample_image_hash>), ...]\n",
    "    '''\n",
    "    dot_products = []\n",
    "    # Get top n similar images based on dot products score\n",
    "    n_top_similar = 8\n",
    "\n",
    "    for key in clip_vectors_json.keys():\n",
    "        if key == ref_file_hash:\n",
    "            # If it is an hash of reference image then ignore the clip vector\n",
    "            continue\n",
    "        # Calculate dot product\n",
    "        sample_clip_vector = np.array(clip_vectors_json[key]['clip_vector'][0])\n",
    "        sample_hash = key\n",
    "        dot_products.append((np.dot(ref_clip_vector, sample_clip_vector), sample_hash))\n",
    "\n",
    "    dot_products.sort(reverse=True)\n",
    "\n",
    "    return dot_products[:n_top_similar]\n",
    "\n",
    "# Specify top n images to display\n",
    "n_top_similar = 8\n",
    "\n",
    "# Run the function\n",
    "top_similar_images = get_hashes_with_similar_clip(ref_file_hash, clip_vectors_json, n_top_similar)\n",
    "print (top_similar_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Reference Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "plt.imshow(Image.open(ref_file_path))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Top Similar Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, n_top_similar, figsize = (20,20))\n",
    "\n",
    "print ('[INFO] Showing Similar Images...')\n",
    "i=0\n",
    "for item in tqdm(top_similar_images):\n",
    "    '''\n",
    "    item has the following structure\n",
    "    [[<dot_product>, <sample_image_hash>, ...]\n",
    "    '''\n",
    "    sample_image_hash = item[1]\n",
    "    file_path = img_list_json[sample_image_hash]['file_path']\n",
    "    ax[i].imshow(Image.open(file_path))\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c518711542db1b7752d0b1005bb6b1db13084b2ce60111ae8895922158ddc3d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
