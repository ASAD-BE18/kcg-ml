{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3kJ9LYUDdBI"
      },
      "source": [
        "# Installing open-clip library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svnTt4UDDhpd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install open_clip_torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BHChZPND1e6"
      },
      "source": [
        "# Cloning GitHub Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiJnUAniDtQc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/kk-digital/kcg-ml.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSCEnTPkDT3N"
      },
      "source": [
        "# OpenClip Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIu2_l57FIHF"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSb1Y61fEyXi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import open_clip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fdns71CFEG4"
      },
      "source": [
        "## Listing All Pre-Trained Models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaV34hG4E0tK",
        "outputId": "ac7a804f-ea0b-4179-fcb9-c1a1c98cfb23"
      },
      "outputs": [],
      "source": [
        "open_clip.list_pretrained()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io_GD6wVFMft"
      },
      "source": [
        "## Text-Image Matching Example.\n",
        "Showing the probaility distribution of a list of texts for single image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YluM478FLlj"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = 'ViT-L-14'\n",
        "PRETRAINED = 'openai'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8OI5XIED9nV",
        "outputId": "b4eaa3fb-d880-4e19-95b2-f60c646a318c"
      },
      "outputs": [],
      "source": [
        "model, _, preprocess = open_clip.create_model_and_transforms(model_name=MODEL_NAME, pretrained=PRETRAINED)\n",
        "tokenizer = open_clip.get_tokenizer(MODEL_NAME)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fiu4DzbZ_84z",
        "outputId": "8a85d8b1-1cc3-4fc1-9ec2-74488470cd82"
      },
      "outputs": [],
      "source": [
        "image = preprocess(Image.open('./kcg-ml/datasets/test-images/example3.jpg')).unsqueeze(0)\n",
        "\n",
        "text = tokenizer([\"pixel art\", \"painting\", \"digital art\"]) # List of texts which will be compared.\n",
        "\n",
        "with torch.no_grad():\n",
        "    image_features = model.encode_image(image)\n",
        "    text_features = model.encode_text(text)\n",
        "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "\n",
        "print(\"Label probs:\", text_probs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDoOGXLnGUPj"
      },
      "source": [
        "## Getting CLIP Image Embeddings for Single Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVYhZVgTF9Jj",
        "outputId": "2acaf23e-8dc4-4619-bad9-dfe1ba2a3810"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    image = preprocess(Image.open('./kcg-ml/datasets/test-images/example3.jpg')).unsqueeze(0).to(device)\n",
        "    emb = model.encode_image(image).cpu().detach().numpy()\n",
        "\n",
        "print(f\"[INFO] CLIP embedding size: {emb.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT8ny-ZRHzth"
      },
      "source": [
        "## Checking the Similarity Between Two Image Using CLIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC-V-KuoGNkv",
        "outputId": "fd8691b3-d248-4296-f5ea-405824430fcb"
      },
      "outputs": [],
      "source": [
        "image1 = preprocess(Image.open('./kcg-ml/datasets/test-images/example1.jpg')).unsqueeze(0).to(device)\n",
        "image2 = preprocess(Image.open('./kcg-ml/datasets/test-images/example2.jpg')).unsqueeze(0).to(device)\n",
        "\n",
        "image_features = model.encode_image(image1)\n",
        "image_2_features = model.encode_image(image2)\n",
        "\n",
        "image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "image_2_features /= image_2_features.norm(dim=-1, keepdim=True)\n",
        "similarity = image_2_features.detach() @ image_features.detach().T\n",
        "print(f'Similarit: {similarity.cpu().detach().numpy()[0][0]:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBWrN2TzJ6pR"
      },
      "source": [
        "## ClipModel Examples\n",
        "â–¶ ClipModel : Module built over OpenClip function, check: https://github.com/kk-digital/kcg-ml/blob/main/examples/ClipTools.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu1mv48cLF-f",
        "outputId": "cf5355bf-d614-4fc3-8ca6-1448fed615aa"
      },
      "outputs": [],
      "source": [
        "!pip install patool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPUAScgOKU76"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0, './kcg-ml/clip_linear_probe_pipeline/')\n",
        "sys.path.insert(0, './kcg-ml/')\n",
        "\n",
        "from examples.ClipTools import ClipModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfeeFzODNyOK"
      },
      "source": [
        "## Creating an Instance of ClipModel Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBQRePaRKoVu"
      },
      "outputs": [],
      "source": [
        "clip_model_instance = ClipModel(clip_model=MODEL_NAME, pretrained=PRETRAINED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJFDH08GN2Cf"
      },
      "source": [
        "## Downloading Model Method Example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4BtxteMLuRC",
        "outputId": "ea84c0eb-a487-40ff-dee9-977a4a2bedc4"
      },
      "outputs": [],
      "source": [
        "clip_model_instance.download_model(MODEL_NAME, PRETRAINED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSFpfaX0ODAR"
      },
      "source": [
        "## Getting Image Embedding Example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbwGlM52MVef"
      },
      "outputs": [],
      "source": [
        "clip_model_instance.encode_image_from_image_file('./kcg-ml/datasets/test-images/example1.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK5fo_2vOWxV"
      },
      "outputs": [],
      "source": [
        "def image_to_bytes(image_path):\n",
        "    with open(image_path, 'rb') as image_file:\n",
        "        bytes_array = bytearray(image_file.read())\n",
        "    return bytes_array\n",
        "\n",
        "clip_model_instance.encode_image_from_image_data(image_to_bytes('./kcg-ml/datasets/test-images/example1.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tU-bhtLONLh"
      },
      "outputs": [],
      "source": [
        "clip_model_instance.encode_image_list(['./kcg-ml/datasets/test-images/example1.jpg', './kcg-ml/datasets/test-images/example2.jpg', './kcg-ml/datasets/test-images/example3.jpg'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
